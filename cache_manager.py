"""
Simple Cache Manager using cachetools for in-memory caching with TTL.
"""

import asyncio
import functools
import logging
from typing import Any, Callable, Optional

from cachetools import TTLCache # pip install cachetools

logger = logging.getLogger(__name__)

# --- Global Cache Instance ---
# Adjust maxsize and ttl as needed
# maxsize: Maximum number of items in the cache
# ttl: Time-to-live in seconds for cache entries
_global_cache = TTLCache(maxsize=1024, ttl=300) # Example: 1024 items, 5 min TTL

# --- Cache Decorator ---
def cached(ttl: Optional[int] = 300, key_prefix: str = "cache"):
    """
    Decorator for caching function results with a specific TTL.

    Handles both synchronous and asynchronous functions.
    Uses a simple key generation based on function name and arguments.

    Args:
        ttl (Optional[int]): Cache time-to-live in seconds. Defaults to 300 (5 minutes).
        key_prefix (str): Prefix for cache keys generated by this decorator instance.
    """
    # Use a specific cache instance per decorator use? Or global? Using global for simplicity.
    # cache = TTLCache(maxsize=1024, ttl=ttl) # Per-decorator cache instance
    cache = _global_cache # Use global cache instance (adjust its TTL if needed, or pass ttl to decorator)

    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        async def async_wrapper(*args: Any, **kwargs: Any) -> Any:
            # Generate cache key based on function name, args, and kwargs
            # Ensure args/kwargs are hashable or convert appropriately
            try:
                key_args = str(args) + str(sorted(kwargs.items()))
                cache_key = f"{key_prefix}:{func.__module__}.{func.__name__}:{key_args}"
            except Exception:
                 # Fallback if args/kwargs cannot be easily stringified/hashed
                 logger.warning(f"Could not generate precise cache key for {func.__name__}. Using basic key.")
                 cache_key = f"{key_prefix}:{func.__module__}.{func.__name__}:fallback"


            # Check cache
            if cache_key in cache:
                cached_result = cache[cache_key]
                logger.debug(f"Cache HIT for key: {cache_key}")
                return cached_result

            # Call the actual function
            logger.debug(f"Cache MISS for key: {cache_key}")
            result = await func(*args, **kwargs)

            # Store result in cache
            # Consider checking if result is None or an error before caching
            if result is not None:
                 # Use the TTL provided to the decorator for this specific entry?
                 # cachetools TTLCache applies TTL globally, not per item via set().
                 # To have per-item TTL with cachetools, you'd need different cache instances
                 # or a more complex cache implementation.
                 # For simplicity, we rely on the global TTL of _global_cache.
                 cache[cache_key] = result

            return result

        @functools.wraps(func)
        def sync_wrapper(*args: Any, **kwargs: Any) -> Any:
            # Generate cache key (same logic as async)
            try:
                key_args = str(args) + str(sorted(kwargs.items()))
                cache_key = f"{key_prefix}:{func.__module__}.{func.__name__}:{key_args}"
            except Exception:
                 cache_key = f"{key_prefix}:{func.__module__}.{func.__name__}:fallback"

            # Check cache
            if cache_key in cache:
                cached_result = cache[cache_key]
                logger.debug(f"Cache HIT for key: {cache_key}")
                return cached_result

            # Call the actual function
            logger.debug(f"Cache MISS for key: {cache_key}")
            result = func(*args, **kwargs)

            # Store result in cache
            if result is not None:
                 cache[cache_key] = result

            return result

        # Return the correct wrapper based on whether the decorated function is async
        if asyncio.iscoroutinefunction(func):
            return async_wrapper
        else:
            return sync_wrapper

    return decorator

# --- Cache Management Functions (Optional) ---
def clear_cache():
    """Clears the entire global cache."""
    _global_cache.clear()
    logger.info("Global cache cleared.")

def get_cache_size() -> int:
    """Returns the current number of items in the global cache."""
    return len(_global_cache)

# Example Usage:
# @cached(ttl=60) # Cache for 60 seconds
# async def fetch_data_from_external_api(user_id: str):
#     # ... fetch data ...
#     return data